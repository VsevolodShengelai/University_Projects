<!DOCTYPE html>
<html lang="ru">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="author" content="Всеволод Шенгелай" />
    <title>В поисках свежести</title>
    <link rel="stylesheet" href="style.css">
    <script src="jquery.js"></script>
    <script src="jslatex.js"></script>
    <script src="script.js"></script>
  </head>
  <body>
    <header></header>
    <main>
      <article>
        <header>
          <h1>В поисках свежести</h1>
          <p>
            20 марта 2010 года началось извержение вулкана Эйяфьядлайёкюдль в
            Исландии. 14 июля 2015 года межпланетная станция New Horizons
            передала на Землю фотографии Плутона. 15 апреля 2019 года случился
            пожар в соборе Парижской Богоматери. Что общего в этих случаях?
          </p>
          <img
            src="images/photos-of-pluto.png"
            width="600"
            alt="Photos of Pluto"
          />
          <p>
            Каждое подобное событие сопровождается всплеском интереса со стороны
            пользователей интернета. Люди хотят не только прочитать о том, что
            произошло, но и взглянуть на фотографии. Они идут в поиск картинок и
            ожидают найти там свежие, актуальные снимки, которые могли не
            существовать ещё несколько часов назад. Интерес возникает неожиданно
            и за несколько дней падает почти до нуля.
          </p>
          <p>
            Особенность ситуации в том, что обычные поисковые механизмы не
            заточены на подобный сценарий. Более того, критерий свежести
            контента противоречит другим важным свойствам хорошего поиска:
            релевантности, авторитетности и т. д. Нужны особые технологии, чтобы
            не просто находить новый контент, но и сохранять баланс в
            результатах.
          </p>
          <p>
            Меня зовут Денис Сахнов, сегодня я расскажу о новом подходе к
            доставке свежего контента до Яндекс.Картинок. А мой коллега Дмитрий
            Кривоконь
            <a href="https://habr.com/ru/users/krivokon/">@krivokon</a>
            поделится подробностями о метриках и ранжировании свежих картинок.
            Вы узнаете о старом и новом подходе к оценке качества. А ещё мы
            напомним о <abbr title="YouTube">YT</abbr> , Logbroker и
            <abbr title="Технология Real Time MapReduce">RTMR</abbr>.
          </p>
          <p>
            Чтобы поиск картинок работал хорошо на той части запросов, ответы на
            которые должны содержать свежий контент, нужно решить следующие
            задачи:
          </p>
          <ol>
            <li>Научиться быстро находить и скачивать свежие картинки.</li>
            <li>Научиться быстро их обрабатывать.</li>
            <li>
              Научиться быстро собирать документы для поиска на базе картинок
              (этот пункт станет понятнее по ходу повествования).
            </li>
            <li>Cформулировать критерии качества поиска свежего контента.</li>
            <li>
              Научиться ранжировать и смешивать контент в выдаче, исходя из
              требований качества.
            </li>
          </ol>
          <p>Начнём с первого пункта</p>
        </header>
        <section>
          <h2>1. Добываем картинки</h2>
          <p>
            В интернете множество сайтов, многие из них что-то регулярно
            публикуют, в том числе картинки. Чтобы люди увидели всё это в поиске
            Картинок, робот должен дойти до сайта и скачать контент. Обычно
            поиск так и работает: мы относительно быстро обходим известные нам
            сайты и получаем новые картинки. Но когда речь идёт о контенте,
            который вдруг становится актуальным прямо сейчас, эта модель не
            справляется. Потому что интернет огромный, невозможно «прямо сейчас»
            скачать HTML-документы всех сайтов в мире и быстро всё это
            переварить. По крайней мере никто в мире такую задачу ещё не решил.
          </p>
          <p>
            Кто-то может представить себе решение проблемы таким образом:
            отслеживать всплески запросов и в первую очередь обрабатывать только
            те источники, которые как-то соответствуют запросам. Но это хорошо
            звучит только на бумаге. Во-первых, чтобы проверить соответствие
            чего-то чему-то, нужно уже иметь на руках контент. Во-вторых, если
            мы начинаем что-то делать после пика запросов, то мы уже опоздали.
            Как бы дико это ни звучало, нужно находить свежий контент до того,
            как в нём возникла потребность. Но как предсказать неожиданное?
          </p>
          <p>
            Правильный ответ: никак. Мы ничего не знаем о графике извержений
            вулканов. Но мы знаем, на каких сайтах обычно появляется свежий и
            полезный контент. С этой стороны мы и пошли. Мы стали применять
            машиннообученную формулу, которая приоритизирует обход нашего робота
            в зависимости от качества и актуальности контента. Да простят нас
            сеошники: в детали тут углубляться не будем. Задача робота — как
            можно быстрее доставить до нас HTML-документы. Только после этого мы
            можем взглянуть на их начинку и найти там новые тексты, ссылки на
            картинки и т. п.
          </p>
          <p>
            Ссылки на картинки — это хорошо, но пока что не особо полезно для
            поиска. Их в первую очередь нужно скачать к нам. Но новых ссылок на
            картинки опять же слишком много, чтобы скачать их мгновенно. И
            проблема тут не только в наших ресурсах: владельцы сайтов тоже не
            хотели бы, чтобы Яндекс их случайно заддосил. Поэтому мы используем
            машинное обучение для приоритизации скачивания картинок. Факторы
            разные, их много, всё объяснять не будем, но для примера можем
            сказать, что частота, с которой картинка появляется на разных
            ресурсах, тоже влияет на приоритет.
          </p>
          <p>
            Теперь у нас есть список ссылок на картинки. Дальше мы их скачиваем
            к себе. При этом используем собственный сервис Logbroker. Эта штука
            выступает в качестве транспортной шины, успешно переживающей
            огромные объёмы трафика. Несколько лет назад наш коллега Алексей
            Озерицкий уже
            <a href="https://habr.com/ru/company/yandex/blog/239823/"
              >рассказывал</a
            >
            об этой технологии на Хабре.
          </p>
          <p>
            На этом первый этап логически завершился. Мы определились с
            источниками и успешно добыли какие-то картинки. Осталось совсем
            чуть-чуть: научиться с ними работать.
          </p>
        </section>
        <section>
          <h2>2. Обрабатываем картинки</h2>
          <p>
            Сами по себе картинки, конечно, полезны, но их ещё нужно
            подготовить. Это происходит так:
          </p>
          <ol>
            <li>
              В сервисе stateless-вычислений RTHub готовятся версии разных
              размеров. Это нужно для поиска, где удобно в результатах
              показывать миниатюры, а исходный контент отдавать с
              сайта-источника по клику.
            </li>
            <li>
              Рассчитываются нейросетевые фичи. В офлайне (т. е. заранее, а не в
              момент ранжирования) на машинках с
              <abbr title="graphics processing unit (грфический процессор)"
                >GPU</abbr
              >
              запускаются нейросетки, результатом работы которых будут векторы
              фич картинки. А также вычисляются значения полезных
              классификаторов: красивости, эстетичности, нежелательного контента
              и многие другие. Всё это нам ещё понадобится.
            </li>
            <li>
              А затем с использованием посчитанной по картинке информации
              склеиваются дубликаты. Это важно: пользователь вряд ли обрадуется
              поисковым результатам, в которых будут преобладать одни и те же
              картинки. При этом они могут немного отличаться: где-то обрезали
              край, где-то добавили водяной знак и т. д. Склейку дубликатов мы
              проводим в два этапа. Сначала происходит грубая кластеризация
              близких картинок с помощью нейросетевых векторов. При этом
              картинки в кластере могут даже не совпадать по смыслу, но это
              позволяет распараллелить дальнейшую работу с ними. Далее уже
              внутри каждого кластера склеиваем дубликаты через поиск опорных
              точек на картинках. Обратите внимание: нейросети отлично ищут
              похожие картинки, но для поиска полных дубликатов эффективнее
              менее «модные» инструменты; нейросетки могут перемудрить и увидеть
              «одинаковое в разном».
            </li>
          </ol>
          <p>
            Итак, к концу этого этапа у нас есть готовые картинки в разных
            вариантах, прошедшие через склейку дубликатов, с предпросчитанными
            нейросетевыми и прочими фичами. Отдаём в ранжирование? Нет, ещё
            рано.
          </p>
        </section>
        <section>
          <h2>3. Собираем картинки в документы</h2>
          <p>
            Документ — это наше название сущности, которая участвует в
            ранжировании. Со стороны пользователя это может выглядеть как ссылка
            на страницу (поиск по сайтам), картинка (поиск картинок), ролик
            (поиск видео), кофеварка (поиск товаров), что-то ещё. Но внутри за
            каждой единицей в выдаче поиска скрывается целый букет разнородной
            информации. В нашем случае — не только сама картинка, её
            нейросетевые и прочие фичи, но и сведения о страницах, где она
            помещена, тексты, которые на этих страницах её описывают, статистика
            поведения пользователей (например, клики по картинке). Всё вместе —
            это и есть документ. И прежде чем перейти непосредственно к поиску,
            документ нужно собрать. И механизм формирования обычной поисковой
            базы картинок здесь не подходит.
          </p>
          <p>
            Основной вызов в том, что разные компоненты документа формируются в
            разное время и в разных местах. Сведения о страницах и текстах может
            загрузить тот же самый Logbroker, но не одновременно с картинками.
            Данные о поведении пользователей в реалтайме поступают через систему
            обработки логов
            <a
              title="Сатья о технологии Real Time MapReduce"
              href="https://habr.com/ru/company/yandex/blog/189362/"
              >RTMR</a
            >
            . И всё это хранится независимо от картинок. Чтобы собрать документ,
            нужно последовательно обойти разные источники данных.
          </p>
        </section>
        <section>
          <h2>4. Измеряем качество</h2>
          <p>
            Общий подход к оптимизации качества поиска начинается с выбора
            метрики. В поиске картинок Яндекса вид метрики примерно такой:
          </p>
          <div class="latex">
            \sum_{i=0}^{n}p_{i}\cdot(r_{i}+f(\omega_{i},...,m_{i}))
          </div>
          <p>
            где<br />
            n — это количество первых картинок (документов) выдачи, которые мы
            оцениваем;<br />
            p_i — вес позиции в выдаче (чем выше позиция, тем больше вес);<br />
            r_i — релевантность (насколько точно картинка соответствует
            запросу);<br />
            w_i … m_i — прочие компоненты качества ответа (свежесть, красота,
            размер...);<br />
            f(...) — модель, которая агрегирует эти компоненты<br />
          </p>
          <p>
            Проще говоря, чем выше в выдаче будут более полезные картинки, тем
            больше сумма в этом выражении.
          </p>
          <p>
            Несколько слов о модели f(...). Она обучается на попарном сравнении
            картинок толокерами. Человек видит запрос и две картинки, а затем
            выбирает лучшую. Если повторить это много-много раз, то модель
            научится предсказывать, какой компонент качества наиболее важен для
            конкретного запроса.
          </p>
          <p>
            К примеру, если запрос о свежих фотографиях чёрной дыры — то
            наибольший коэффициент у компонента свежести. А если о тропическом
            острове — то у красоты, потому что мало кто ищет любительские
            фотографии страшненьких островов, обычно нужны именно
            привлекательные картинки. Чем визуально лучше выглядит выдача
            картинок в таких случаях, тем больше вероятность, что человек
            продолжит пользоваться сервисом. Но не будем отвлекаться на это.
          </p>
          <!-- <h2>, <p>, <sub>, <ruby>, <rt> -->
        </section>
        <section>
          <h2>5. Ранжируем</h2>
          <p>
            Напомню, выше мы описали переход от первого подхода к оценке
            качества поиска картинок ко второму: от подмешивания результатов к
            ежедневному пополнению приёмочной корзины свежими запросами.
            Парадигма сменилась — понадобились изменения и самих алгоритмов. Это
            достаточно непросто объяснить читателям со стороны, но я попробую.
            Если останутся вопросы — смело задавайте их в комментариях.
          </p>
          <p>
            Раньше методы были реализованы по аналогии с решением, о котором
            <a href="https://habr.com/ru/company/yandex/blog/329946/"
              >рассказывал</a
            >
            наш коллега Алексей Шаграев. Есть основной источник документов
            (основной поисковый индекс). А ещё есть дополнительный источник
            свежих документов, для которых критична скорость попадания в поиск.
            Документы из разных источников нельзя было ранжировать по единой
            логике, поэтому мы по достаточно нетривиальной схеме подмешивали
            документы из свежего источника в основную выдачу. Далее сравнивали
            метрики основной выдачи без дополнительных документов и с ними.
          </p>
          <p>
            Сейчас ситуация другая. Да, источники по-прежнему физически разные,
            но с точки зрения метрик совершенно неважно, откуда именно пришла
            свежая картинка. Она может и из основного источника попасть, если
            обычный робот успел до неё добраться. В этом случае метрики будут
            идентичны той ситуации, когда эта же картинка добралась до выдачи
            через отдельный источник. В новом подходе есть содержательная
            свежесть запроса и результата, а архитектура источников уже не так
            важна. В результате и основные, и свежие документы ранжируются с
            помощью одной и той же модели, что позволяет нам подмешивать свежие
            картинки в выдачу по существенно более простой логике, чем раньше:
            путём простой сортировки по значению на выходе единой модели.
            Конечно же, это отразилось и на качестве.
          </p>
          <hr />
        </section>
        <footer>
          <p>
            <b
              >В одном посте невозможно подробно рассказать обо всей работе,
              которую проделала команда поиска картинок Яндекса. Надеемся, у нас
              получилось объяснить, в чём особенности поиска свежих картинок. И
              зачем нужны изменения на всех этапах поиска, чтобы пользователи
              смогли быстро найти свежие фотографии Плутона или любую другую
              актуальную информацию.
            </b>
          </p>
          <p>
            <b>Автор </b
            ><a target="_blank" href="https://habr.com/ru/users/imgbase/"
              >@imgbase</a
            >
          </p>
          <p>
            <b>Разработчик </b
            ><a
              target="_blank"
              href="https://habr.com/ru/company/yandex/profile/"
              >Компания Яндекс</a
            >
          </p>
          <article>
            <h3>Коментария(3):</h3>
            <p>
              <a target="_blank" href="https://habr.com/ru/users/Kriminalist/"
                >@Kriminalist</a
              >
              <span class="date">2020-08-13 12:01</span>
            </p>
            <blockquote>
              <i
                >Нет уж, давайте как раз отвлечемся на именно этот момент.
                Фактически получается, что ни о какой персонализации выдачи речь
                не идет, поиск заточен под «обычно нужны», и у вас работает
                система с положительной обратной связью — чем больше выдачи
                вверху, тем выше рейтинг такой выдачи. Т.е. мейнстрим поглощает
                и подавляет «любительские фотографии страшненьких островов», а
                практической возможности выйти из этого потока у пользователя
                нет. И если мне нужны реальные фото без прикрас — я буду
                страдать.</i
              >
            </blockquote>
            <p>
              <a target="_blank" href="https://habr.com/ru/users/imgbase/"
                >@imgbase</a
              >
              <span class="date">2020-08-13 14:32</span>
            </p>
            <blockquote>
              <i
                >Запрос можно конкретизировать, чтобы помочь поиску понять
                потребности. Например, по запросу [любительские фотографии с
                островов] уже меньше «прикрас». Ещё важно понимать, что красота
                это не синоним фотошопа. Даже любительские фотографии могут быть
                красивыми и удачными. И наоборот: постановочные могут не пройти
                по критерию привлекательности.</i
              >
            </blockquote>
            <p>
              <a target="_blank" href="https://habr.com/ru/users/sumanai/"
                >@sumanai</a
              >
              <span class="date">2020-08-13 13:52</span>
            </p>
            <blockquote>
              <i
                >А зачем тогда нейросети? Неужели нейросети быстрее и меньше
                нагружают оборудование, нежели чем старые добрые алгоритмы?</i
              >
            </blockquote>
          </article>
        </footer>
      </article>
    </main>
    <footer></footer>
  </body>
</html>
